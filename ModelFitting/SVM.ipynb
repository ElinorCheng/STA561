{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking AAPL Daily stock data as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "freq = 'Daily'\n",
    "stock = 'AAPL'\n",
    "\n",
    "price = pd.read_csv('../encode_price/'+freq+'/'+stock+'.csv')\n",
    "price = price.loc[(price.Date<='2019-12-31')&(price.Date>='2010-01-04'),:]\n",
    "price = price.loc[(price.Date>='2010-01-04'),:]\n",
    "y = price.direction2.shift(-1).values[:-1]\n",
    "predictors = pd.read_csv('../predictors/Merged/'+freq+'/'+stock+'.csv')\n",
    "NLP = pd.read_csv('../predictors/NLP/'+freq+'/NYT_macro_SA.csv')\n",
    "predictors = pd.merge(predictors,NLP,how='left',on=['Date'])\n",
    "predictors = predictors.loc[predictors.Date <= '2019-12-31',:]\n",
    "predictors.set_index('Date',inplace=True)\n",
    "predictors.fillna(0,inplace=True) \n",
    "X = predictors.values[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix,classification_report,f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.04      0.07       337\n",
      "         1.0       0.34      0.99      0.50       166\n",
      "\n",
      "    accuracy                           0.35       503\n",
      "   macro avg       0.60      0.51      0.29       503\n",
      "weighted avg       0.69      0.35      0.22       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=False)\n",
    "sm = SMOTE(sampling_strategy='minority',random_state=42,k_neighbors=5)\n",
    "X_res,y_res = sm.fit_resample(X_train,y_train)\n",
    "pipe = make_pipeline(StandardScaler(),SVC(kernel='linear'))\n",
    "pipe.fit(X_res,y_res)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.07      0.12       337\n",
      "         1.0       0.33      0.92      0.48       166\n",
      "\n",
      "    accuracy                           0.35       503\n",
      "   macro avg       0.48      0.49      0.30       503\n",
      "weighted avg       0.54      0.35      0.24       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=False)\n",
    "pipe = make_pipeline(StandardScaler(),SVC(kernel='poly',degree=4))\n",
    "pipe.fit(X_res,y_res)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.05      0.10       337\n",
      "         1.0       0.33      0.95      0.49       166\n",
      "\n",
      "    accuracy                           0.35       503\n",
      "   macro avg       0.51      0.50      0.30       503\n",
      "weighted avg       0.57      0.35      0.23       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.99      0.80       337\n",
      "         1.0       0.20      0.01      0.01       166\n",
      "\n",
      "    accuracy                           0.66       503\n",
      "   macro avg       0.43      0.50      0.40       503\n",
      "weighted avg       0.51      0.66      0.54       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=False)\n",
    "pipe = make_pipeline(StandardScaler(),SVC(kernel='rbf'))\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.37      0.46       337\n",
      "         1.0       0.27      0.46      0.34       166\n",
      "\n",
      "    accuracy                           0.40       503\n",
      "   macro avg       0.43      0.42      0.40       503\n",
      "weighted avg       0.48      0.40      0.42       503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,shuffle=False)\n",
    "pipe = make_pipeline(StandardScaler(),SVC(kernel= 'sigmoid'))\n",
    "pipe.fit(X_train,y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above result, we can find that RBF kernel outperform. So, we will select Sigmoid kernel for the future tuning purpose."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the part, we will use the weighted F1-score to evaluate the classification problem, which will include the biase situation into the consideration, which will place a penalty on the biased prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_list = ['SMA','EMA','STOCH_k','STOCK_d','RSI','MFI','SAR','AD','MACD','MACD_Signal','MACD_Histo','VWAP','SPY','NDAQ','PC1','PC2']\n",
    "funda_list = ['pcf','PEG_trailing','dpr','npm','gpm','roa','roe','capital_ratio','de_ratio','cash_ratio','curr_ratio','inv_turn','pay_turn','sale_nwc','rd_sale','accrual']\n",
    "macro_list = ['gdpr1','gdpr2','cpi','bond20yr','bond30yr','fedfunds','cpir','wpir','unemp','employ']\n",
    "nlp_list = ['Pos_lag2','Pos_lag3','Neg_lag1','Neg_lag2','Neg_lag3','Neu_lag1','Neu_lag2','Neu_lag3']\n",
    "stock_list = ['AAPL','AMZN','BRK-B','GOOG','JNJ','META','MSFT','NVDA','TSLA','V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_score = dict()\n",
    "for j in stock_list:\n",
    "    freq = 'Daily'\n",
    "    stock = j\n",
    "    price = pd.read_csv('../encode_price/'+freq+'/'+stock+'.csv')\n",
    "    price = price.loc[(price.Date<='2019-12-31')&(price.Date>='2010-01-04'),:]\n",
    "    price = price.loc[(price.Date>='2010-01-04'),:]\n",
    "    y = price.direction2.shift(-1).values[:-1]\n",
    "    predictors = pd.read_csv('../predictors/Merged/'+freq+'/'+stock+'.csv')\n",
    "    NLP = pd.read_csv('../predictors/NLP/Daily/NYT_macro_SA.csv')\n",
    "    predictors = pd.merge(predictors,NLP,how='left',on=['Date'])\n",
    "    predictors = predictors.loc[predictors.Date <= '2019-12-31',:]\n",
    "    predictors.set_index('Date',inplace=True)\n",
    "    predictors.fillna(0,inplace=True) \n",
    "    X = predictors.values[:-1]\n",
    "    alpha_score = []\n",
    "    for i in range(5,49,5):\n",
    "        cv = 3\n",
    "        scores = []\n",
    "        tscv = TimeSeriesSplit(n_splits=cv)\n",
    "        for train_index, test_index in tscv.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            pipe = make_pipeline(MinMaxScaler(),SVC(kernel='rbf'))\n",
    "            sfs = SequentialFeatureSelector(pipe,n_jobs = -1,n_features_to_select=i,scoring='f1_weighted')\n",
    "            sfs.fit(X_train,y_train)\n",
    "            X_train = sfs.transform(X_train)\n",
    "            pipe.fit(X_train,y_train)\n",
    "            X_test =  sfs.transform(X_test)\n",
    "            y_pred = pipe.predict(X_test)\n",
    "            scores.append(f1_score(y_pred,y_test,average = 'weighted'))\n",
    "        average_score = np.mean(scores)\n",
    "        alpha_score.append(average_score)\n",
    "    print(j,alpha_score)\n",
    "    stock_score[j] = alpha_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f5ca7f1e19f63aad61e7f105267048d1a47f29c947be0f4c6ffca5d2ac1d455d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
