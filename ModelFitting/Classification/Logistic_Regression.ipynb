{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report,zero_one_loss,recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic with traditional train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logi(stock, freq):\n",
    "    # freq = 'Weekly'\n",
    "    # stock = 'AAPL'\n",
    "    price = pd.read_csv('../../encode_price/'+freq+'/'+stock+'.csv')\n",
    "    price = price[(price['Date']>='2010-01-01') & (price['Date']<='2020-02-01')]\n",
    "    y = price.direction2.shift(-1).values[:-1]\n",
    "    predictors = pd.read_csv('../../predictors/Merged/'+freq+'/'+stock+'.csv',index_col='Date')\n",
    "    predictors.fillna(0,inplace=True)\n",
    "    X = predictors.values[:-1,]\n",
    "    X.shape\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,shuffle=False)\n",
    "\n",
    "    pipe = make_pipeline(MinMaxScaler(),LogisticRegression(dual=True,penalty = 'l2',solver='liblinear'))\n",
    "    pipe.fit(X_train,y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    print(stock,'/',freq,'\\n',classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- logistic with cross validation using tscv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logi_cv(stock, freq, cv=5):\n",
    "    # freq = 'Weekly'\n",
    "    # stock = 'AAPL'\n",
    "    price = pd.read_csv('../../encode_price/'+freq+'/'+stock+'.csv')\n",
    "    price = price[(price['Date']>='2010-01-01') & (price['Date']<='2020-02-01')]\n",
    "    y = price.direction2.shift(-1).values[:-1]\n",
    "    predictors = pd.read_csv('../../predictors/Merged/'+freq+'/'+stock+'.csv',index_col='Date')\n",
    "    predictors.fillna(0,inplace=True)\n",
    "    X = predictors.values[:-1,]\n",
    "    X.shape\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=cv)\n",
    "    scores = []\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        pipe = make_pipeline(MinMaxScaler(),LogisticRegression(dual=True,penalty = 'l2',solver='liblinear'))\n",
    "        pipe.fit(X_train,y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        score = classification_report(y_test,y_pred,output_dict=True)\n",
    "        scores.append(score['weighted avg']['f1-score'])\n",
    "\n",
    "    average_score = np.mean(scores)\n",
    "    print(stock,'/',freq,'\\n','Average F1-score:', average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_list = ['AAPL','MSFT','GOOG','AMZN','NVDA','BRK-B','TSLA','META','JNJ','V']\n",
    "freq_list = ['Daily','Weekly','Monthly']\n",
    "\n",
    "import sys \n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "\n",
    "\n",
    "with open('./result of logi/result_of_logi.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for name in stock_list:\n",
    "        for freq in freq_list:\n",
    "            logi(name, freq)\n",
    "    \n",
    "    sys.stdout = sys.__stdout__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./result of logi/result_of_logi_with_cv.txt', 'w') as f:\n",
    "    sys.stdout = f\n",
    "    \n",
    "    for name in stock_list:\n",
    "        for freq in freq_list:\n",
    "            logi_cv(name, freq, 3)\n",
    "    \n",
    "    sys.stdout = sys.__stdout__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the result in the result folder under Classification\n",
    "\n",
    "In general, the monthly F1 accuracy shows higher than the daily/weekly one, and for some stocks, the monthly F1 could be nearly 0.8, which indicates the model could be useful to tell the trend of stock price. In average, the monthly F1 is around 0.6, which is still good for trade strategy. In addition, our model has a robustly great result for visa among the stock list we test, and we believe we could based on this model to find the suitable stock and based on them build response trade strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
